{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preparing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzMEeOkavMjV"
      },
      "source": [
        "## 1. Setup dataset and libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ebk9Wc27HcE"
      },
      "source": [
        "### import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iD-zvW7a7HF_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import ast\n",
        "import string\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "folder_path = \"..../dataset/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4cZOKjENEX2"
      },
      "source": [
        "## 2. Read dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgehaIVRNE87",
        "outputId": "fddff09f-712f-4607-e7d1-ed7e8734d611"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21115</th>\n",
              "      <td>&lt;br /&gt;&lt;br /&gt;Artisticly shot, actors portray ex...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7079</th>\n",
              "      <td>I've seen the 1973 movie Lost Horizons and rea...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11220</th>\n",
              "      <td>Second movie in the boxset. Originally titled ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49501</th>\n",
              "      <td>Nick Cage is Randall Raines, a retired car thi...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38153</th>\n",
              "      <td>This film rocks...so hard...&lt;br /&gt;&lt;br /&gt;The ca...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "21115  <br /><br />Artisticly shot, actors portray ex...  positive\n",
              "7079   I've seen the 1973 movie Lost Horizons and rea...  positive\n",
              "11220  Second movie in the boxset. Originally titled ...  negative\n",
              "49501  Nick Cage is Randall Raines, a retired car thi...  positive\n",
              "38153  This film rocks...so hard...<br /><br />The ca...  positive"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_ori = pd.read_csv( folder_path+\"IMDB Dataset of 50K Movie Reviews/IMDB Dataset.csv\" )\n",
        "df_ori.sample( 5 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_llk5niTX2s",
        "outputId": "d00d7be7-1c64-4db8-8340-eb280daa8e48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "review       object\n",
              "sentiment    object\n",
              "dtype: object"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_ori.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvJQC9TdStFS",
        "outputId": "6658e83a-1d3d-4d98-ec2d-31ac35142642"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "positive    25000\n",
              "negative    25000\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_ori.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7iyLHqsTf4G",
        "outputId": "2ae43db7-9b88-44a0-d3ad-afc516cf7650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total data reviews: 50000\n"
          ]
        }
      ],
      "source": [
        "print( \"total data reviews:\",len( df_ori ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxBDzBGNiJUD"
      },
      "source": [
        "## 3. Data Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2YvX3MpvjFb"
      },
      "source": [
        "### function for sampling data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qb0FzkPpxjzx"
      },
      "outputs": [],
      "source": [
        "# to do sampling data for the selected dataset\n",
        "\n",
        "def stratified_sampling( dtframe, column_category, number_data_each_class ):\n",
        "  # get selected column values\n",
        "  classes = dtframe[ column_category ].unique()\n",
        "\n",
        "  # vessel for collected data\n",
        "  collected_data = []\n",
        "\n",
        "  # for each class get their sample data randomly\n",
        "  for cls in classes:\n",
        "    # sampling the data from a class\n",
        "    chosen_data = dtframe[ dtframe[ column_category ] == cls ].sample( n=number_data_each_class, random_state=42 )\n",
        "\n",
        "    # save selected data into the temporary vessel\n",
        "    collected_data.append( chosen_data )\n",
        "  # end loop\n",
        "\n",
        "  # concate all the collected data\n",
        "  merged_data = pd.concat( collected_data, ignore_index=True )\n",
        "\n",
        "  # randomize the order\n",
        "  merged_data = merged_data.sample(frac=1).reset_index( drop=True )\n",
        "\n",
        "  # return the final data\n",
        "  return merged_data\n",
        "# end func"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwTC3bZZvmDS"
      },
      "source": [
        "### do data sampling with previous function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iDDXZlmC-tQq",
        "outputId": "331b5850-60c6-4dfa-b7fe-899920106e69"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The trouble with the book, \"Memoirs of a Geish...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Take someone you love or want to love and go s...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Cut\" is a film about some film students makin...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>History and experience over the past couple of...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"Death Bed:The Bed That Eats\" is a supremely b...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  The trouble with the book, \"Memoirs of a Geish...  negative\n",
              "1  Take someone you love or want to love and go s...  positive\n",
              "2  \"Cut\" is a film about some film students makin...  negative\n",
              "3  History and experience over the past couple of...  negative\n",
              "4  \"Death Bed:The Bed That Eats\" is a supremely b...  positive"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# do data sampling\n",
        "sampled_data = stratified_sampling( df_ori, 'sentiment', 5000 )\n",
        "\n",
        "# check the collected sampled data\n",
        "sampled_data.head( 5 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUz1dHsxotoA"
      },
      "source": [
        "### Saving current sampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uSDMKO-nmK2-"
      },
      "outputs": [],
      "source": [
        "# # save seledcted data into the csv file\n",
        "# sampled_data.to_csv( folder_path+\"sampled_movie_dataset.csv\", index=False )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SooSBRtbwXrt"
      },
      "source": [
        "## 4. Preprocessing Step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z40Pn6ESv36O"
      },
      "source": [
        "### read sampled dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "Yfj1UPfZ1EpO",
        "outputId": "6cf778bf-c6e5-4fd5-a6ef-c2eeb597c53e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of data: 10000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>preprocessed_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I know little or nothing about astronomy, but ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(As a note, I'd like to say that I saw this mo...</td>\n",
              "      <td>negative</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The year 2000 had been a bad year for indian f...</td>\n",
              "      <td>positive</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you pack all the clichés about city firefig...</td>\n",
              "      <td>negative</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How many of us have read a book or seen a play...</td>\n",
              "      <td>positive</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment   \n",
              "0  I know little or nothing about astronomy, but ...  positive  \\\n",
              "1  (As a note, I'd like to say that I saw this mo...  negative   \n",
              "2  The year 2000 had been a bad year for indian f...  positive   \n",
              "3  If you pack all the clichés about city firefig...  negative   \n",
              "4  How many of us have read a book or seen a play...  positive   \n",
              "\n",
              "  preprocessed_review  \n",
              "0                None  \n",
              "1                None  \n",
              "2                None  \n",
              "3                None  \n",
              "4                None  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# read the saved sampled data from previous data sampling step\n",
        "df_sampled = pd.read_csv( folder_path+\"sampled_movie_dataset.csv\" )\n",
        "\n",
        "# check the number of selected data\n",
        "print( \"number of data:\",len( df_sampled ) )\n",
        "\n",
        "# create new column to store preprocessed text reviews\n",
        "df_sampled['preprocessed_review'] = None\n",
        "\n",
        "# check current dataframe conditions\n",
        "df_sampled.head( 5 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ApeFQMDAo_0"
      },
      "source": [
        "### setups objects, list, and functions to be used on preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYGou-aa71s4",
        "outputId": "994782d7-f88a-4d8f-b0cb-7754f0300716"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\medin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\medin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# create regex pattern for numerical and punctuation removal\n",
        "word_pattern = re.compile(r\"[^A-Za-z]+\")\n",
        "\n",
        "# download tokenizer and stopwords\n",
        "nltk.download( 'punkt' )\n",
        "nltk.download( 'stopwords' )\n",
        "\n",
        "# get list of stopwords and punctuation chars\n",
        "list_stopwords = set( stopwords.words( 'english' ) )\n",
        "\n",
        "# create a Porter Stemmer instance\n",
        "porter_stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmqkuJqZv-Bb"
      },
      "source": [
        "### additional functions to help preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9UJ3mttywaJi"
      },
      "outputs": [],
      "source": [
        "# function to remove any html tags\n",
        "def remove_html_tags( review_text ):\n",
        "  # only remove the tags when a review text contains html tags\n",
        "  if '<' in review_text and '>' in review_text:\n",
        "    # replace a <br> tags with a space\n",
        "    text_without_br = review_text.replace( \"<br />\", \" \" )\n",
        "\n",
        "    # remove other html tags\n",
        "    return BeautifulSoup( text_without_br, \"html.parser\" ).get_text()\n",
        "  else:\n",
        "    return review_text\n",
        "  # end if\n",
        "# end function\n",
        "\n",
        "# merge all pre processing functions into a function\n",
        "def preprocessing_text( input_text ):\n",
        "  # 1. remove the html tags from input text\n",
        "  removal_html_result = remove_html_tags( input_text )\n",
        "\n",
        "  # 2. Sentence segmentation, breaking every document into sentences\n",
        "  segmentation_result = sent_tokenize( removal_html_result )\n",
        "\n",
        "  # 3. Tokenisasi; case folding; removal of punctuation and numerical character; stopword removal; word stemming\n",
        "  # loop all sentences for pre processing on each words\n",
        "  final_result = []\n",
        "  unique_words = []\n",
        "  for sentence in segmentation_result:\n",
        "    # default tokenized sentence\n",
        "    tokenized_words = []\n",
        "\n",
        "    # 3. Tokenizing\n",
        "    # loop all tokenized sentence\n",
        "    for token in word_tokenize( sentence ):\n",
        "      # 4. Case folding\n",
        "      word_1 = token.lower()\n",
        "\n",
        "      # 5. Punctuation and numerical character removal\n",
        "      # ref: https://stackoverflow.com/questions/5843518/remove-all-special-characters-punctuation-and-spaces-from-string\n",
        "      word_2 = word_pattern.sub( '', word_1 )\n",
        "\n",
        "      # 6. stopwords removal, also remove any empty word\n",
        "      # ref: https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
        "      if not word_2 in list_stopwords and len( word_2 ) > 0:\n",
        "\n",
        "        # 7. word stemming (Porter’s Stemming)\n",
        "        # (?) maybe also try lemmatization\n",
        "        # ref: https://www.geeksforgeeks.org/introduction-to-stemming/\n",
        "        word_3 = porter_stemmer.stem( word_2 )\n",
        "\n",
        "        # store the pre processed word\n",
        "        tokenized_words.append( word_3 )\n",
        "      # end if\n",
        "    # end loop tokenized sentence\n",
        "\n",
        "    # store all tokenized sentences into the final word list\n",
        "    final_result.append( tokenized_words )\n",
        "  # end loop sentence list\n",
        "\n",
        "  # return final result of preprocessed input text\n",
        "  return final_result\n",
        "# end if"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KePMyNPXwDgd"
      },
      "source": [
        "### do preprocessing and convert sentiment value from string into number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "Tb1Ybd6fgBEG",
        "outputId": "a376c98c-9eda-414b-8294-56a0ab34bac8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\medin\\AppData\\Local\\Temp\\ipykernel_13456\\151062123.py:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  return BeautifulSoup( text_without_br, \"html.parser\" ).get_text()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>preprocessed_review</th>\n",
              "      <th>sentiment_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I know little or nothing about astronomy, but ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[[know, littl, noth, astronomi, nevertheless, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(As a note, I'd like to say that I saw this mo...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[[note, like, say, saw, movi, annual, church, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The year 2000 had been a bad year for indian f...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[[year, bad, year, indian, film, due, lack, qu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you pack all the clichés about city firefig...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[[pack, clich, citi, firefight, minut, ladder]...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How many of us have read a book or seen a play...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[[mani, us, read, book, seen, play, movi, vers...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment   \n",
              "0  I know little or nothing about astronomy, but ...  positive  \\\n",
              "1  (As a note, I'd like to say that I saw this mo...  negative   \n",
              "2  The year 2000 had been a bad year for indian f...  positive   \n",
              "3  If you pack all the clichés about city firefig...  negative   \n",
              "4  How many of us have read a book or seen a play...  positive   \n",
              "\n",
              "                                 preprocessed_review  sentiment_number  \n",
              "0  [[know, littl, noth, astronomi, nevertheless, ...                 1  \n",
              "1  [[note, like, say, saw, movi, annual, church, ...                 0  \n",
              "2  [[year, bad, year, indian, film, due, lack, qu...                 1  \n",
              "3  [[pack, clich, citi, firefight, minut, ladder]...                 0  \n",
              "4  [[mani, us, read, book, seen, play, movi, vers...                 1  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# preprocess all data\n",
        "df_sampled['preprocessed_review'] = df_sampled['review'].apply( lambda review_text: preprocessing_text( review_text ) )\n",
        "\n",
        "# convert sentiment from string into number\n",
        "df_sampled['sentiment_number'] = df_sampled['sentiment'].map( { 'negative': 0, 'positive': 1 } )\n",
        "\n",
        "# check data\n",
        "df_sampled.head( 5 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mZyMOh0wtkG"
      },
      "source": [
        "## 5. Feature Extraction Step\n",
        "\n",
        "ref:\n",
        "- https://www.analyticsvidhya.com/blog/2021/09/what-are-n-grams-and-how-to-implement-them-in-python/\n",
        "- https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/\n",
        "- ChatGPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv7YPnuexT88"
      },
      "source": [
        "## convert tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhUHkIAhwQUw"
      },
      "source": [
        "### functions to convert tokens into form tat able to be processed in CountVector function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PAw4PtF0zBLz"
      },
      "outputs": [],
      "source": [
        "# to merge all tokens from a review into one long textual value with divider of each sentence is `.`\n",
        "def merge_tokens_into_sentences( input_sentences, separate_sentence=False ):\n",
        "  # default vessel for joined tokens\n",
        "  joined_tokens_list = []\n",
        "\n",
        "  # loop all sentence\n",
        "  for tokens in input_sentences:\n",
        "    if separate_sentence:\n",
        "      # merge tokens into one sentence; and add it into the merged token list\n",
        "      joined_tokens_list.append( \" \".join( tokens ) + \".\" )\n",
        "    else:\n",
        "      # merge tokens into one sentence; and add it into the merged token list\n",
        "      joined_tokens_list.append( \" \".join( tokens ) )\n",
        "    # end if\n",
        "  # end loop\n",
        "\n",
        "  # return final merged tokens\n",
        "  return \" \".join( joined_tokens_list )\n",
        "# end func"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsBxpkBiwa_s"
      },
      "source": [
        "### apply the previous function into preprocessed data review and store it into different column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQO9AT3mpwIK",
        "outputId": "19068fad-3b41-478f-c585-a3e431e7f9b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>merged_tokens_one</th>\n",
              "      <th>merged_tokens_many</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I know little or nothing about astronomy, but ...</td>\n",
              "      <td>know littl noth astronomi nevertheless first l...</td>\n",
              "      <td>know littl noth astronomi nevertheless first l...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(As a note, I'd like to say that I saw this mo...</td>\n",
              "      <td>note like say saw movi annual church camp enti...</td>\n",
              "      <td>note like say saw movi annual church camp enti...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The year 2000 had been a bad year for indian f...</td>\n",
              "      <td>year bad year indian film due lack qualiti ima...</td>\n",
              "      <td>year bad year indian film due lack qualiti ima...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you pack all the clichés about city firefig...</td>\n",
              "      <td>pack clich citi firefight minut ladder stori h...</td>\n",
              "      <td>pack clich citi firefight minut ladder. stori ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How many of us have read a book or seen a play...</td>\n",
              "      <td>mani us read book seen play movi version came ...</td>\n",
              "      <td>mani us read book seen play movi version came ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review   \n",
              "0  I know little or nothing about astronomy, but ...  \\\n",
              "1  (As a note, I'd like to say that I saw this mo...   \n",
              "2  The year 2000 had been a bad year for indian f...   \n",
              "3  If you pack all the clichés about city firefig...   \n",
              "4  How many of us have read a book or seen a play...   \n",
              "\n",
              "                                   merged_tokens_one   \n",
              "0  know littl noth astronomi nevertheless first l...  \\\n",
              "1  note like say saw movi annual church camp enti...   \n",
              "2  year bad year indian film due lack qualiti ima...   \n",
              "3  pack clich citi firefight minut ladder stori h...   \n",
              "4  mani us read book seen play movi version came ...   \n",
              "\n",
              "                                  merged_tokens_many sentiment   \n",
              "0  know littl noth astronomi nevertheless first l...  positive  \\\n",
              "1  note like say saw movi annual church camp enti...  negative   \n",
              "2  year bad year indian film due lack qualiti ima...  positive   \n",
              "3  pack clich citi firefight minut ladder. stori ...  negative   \n",
              "4  mani us read book seen play movi version came ...  positive   \n",
              "\n",
              "   sentiment_number  \n",
              "0                 1  \n",
              "1                 0  \n",
              "2                 1  \n",
              "3                 0  \n",
              "4                 1  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# merge reviews in two different ways\n",
        "\n",
        "# a) create tokens from each sentence from one review\n",
        "df_sampled['merged_tokens_many'] = df_sampled['preprocessed_review'].apply( lambda review_text: merge_tokens_into_sentences( review_text, separate_sentence=True ) )\n",
        "\n",
        "# b) create tokens from one review (not separated based on their sentence)\n",
        "df_sampled['merged_tokens_one']  = df_sampled['preprocessed_review'].apply( lambda review_text: merge_tokens_into_sentences( review_text, separate_sentence=False ) )\n",
        "\n",
        "# c) re-arrange columns order\n",
        "df_sampled = df_sampled[ [ 'review', 'merged_tokens_one', 'merged_tokens_many', 'sentiment', 'sentiment_number' ] ]\n",
        "\n",
        "# save selected data into the csv file\n",
        "df_sampled.to_csv( folder_path+\"processed_movie_dataset.csv\", index=False )\n",
        "\n",
        "# check result\n",
        "df_sampled.head( 5 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### split data into train and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution in the original sampled dataset:\n",
            "sentiment_number\n",
            "1    0.5\n",
            "0    0.5\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Class distribution in the training set:\n",
            "sentiment_number\n",
            "0    0.5\n",
            "1    0.5\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Class distribution in the test set:\n",
            "sentiment_number\n",
            "0    0.5\n",
            "1    0.5\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# set into y and X variables\n",
        "y_data = df_sampled['sentiment_number'].copy()\n",
        "X_data = df_sampled.copy().drop( 'sentiment_number', axis=1 )\n",
        "\n",
        "# split into train and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split( X_data, y_data, test_size=0.2, random_state=42, stratify=y_data )\n",
        "\n",
        "# merge the X and y variables back into separate DataFrames\n",
        "df_train = pd.concat( [ X_train, y_train ], axis=1 )\n",
        "df_test  = pd.concat( [ X_test, y_test ], axis=1 )\n",
        "\n",
        "# save each train and test set into separate csv file\n",
        "df_train.to_csv( folder_path+\"processed_movie_dataset_train.csv\", index=False )\n",
        "df_test.to_csv( folder_path+\"processed_movie_dataset_test.csv\", index=False )\n",
        "\n",
        "# check the class distribution to verify stratification\n",
        "print( \"Class distribution in the original sampled dataset:\" )\n",
        "print( df_sampled['sentiment_number'].value_counts( normalize=True ) )\n",
        "print( \"\" )\n",
        "print( \"Class distribution in the training set:\" )\n",
        "print( df_train['sentiment_number'].value_counts( normalize=True ) )\n",
        "print( \"\" )\n",
        "print( \"Class distribution in the test set:\" )\n",
        "print( df_test['sentiment_number'].value_counts( normalize=True ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### try to read original preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>merged_tokens_one</th>\n",
              "      <th>merged_tokens_many</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I know little or nothing about astronomy, but ...</td>\n",
              "      <td>know littl noth astronomi nevertheless first l...</td>\n",
              "      <td>know littl noth astronomi nevertheless first l...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(As a note, I'd like to say that I saw this mo...</td>\n",
              "      <td>note like say saw movi annual church camp enti...</td>\n",
              "      <td>note like say saw movi annual church camp enti...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The year 2000 had been a bad year for indian f...</td>\n",
              "      <td>year bad year indian film due lack qualiti ima...</td>\n",
              "      <td>year bad year indian film due lack qualiti ima...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you pack all the clichés about city firefig...</td>\n",
              "      <td>pack clich citi firefight minut ladder stori h...</td>\n",
              "      <td>pack clich citi firefight minut ladder. stori ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How many of us have read a book or seen a play...</td>\n",
              "      <td>mani us read book seen play movi version came ...</td>\n",
              "      <td>mani us read book seen play movi version came ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review   \n",
              "0  I know little or nothing about astronomy, but ...  \\\n",
              "1  (As a note, I'd like to say that I saw this mo...   \n",
              "2  The year 2000 had been a bad year for indian f...   \n",
              "3  If you pack all the clichés about city firefig...   \n",
              "4  How many of us have read a book or seen a play...   \n",
              "\n",
              "                                   merged_tokens_one   \n",
              "0  know littl noth astronomi nevertheless first l...  \\\n",
              "1  note like say saw movi annual church camp enti...   \n",
              "2  year bad year indian film due lack qualiti ima...   \n",
              "3  pack clich citi firefight minut ladder stori h...   \n",
              "4  mani us read book seen play movi version came ...   \n",
              "\n",
              "                                  merged_tokens_many sentiment   \n",
              "0  know littl noth astronomi nevertheless first l...  positive  \\\n",
              "1  note like say saw movi annual church camp enti...  negative   \n",
              "2  year bad year indian film due lack qualiti ima...  positive   \n",
              "3  pack clich citi firefight minut ladder. stori ...  negative   \n",
              "4  mani us read book seen play movi version came ...  positive   \n",
              "\n",
              "   sentiment_number  \n",
              "0                 1  \n",
              "1                 0  \n",
              "2                 1  \n",
              "3                 0  \n",
              "4                 1  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "read_ori = pd.read_csv( folder_path+\"processed_movie_dataset.csv\" )\n",
        "read_ori.head( 5 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### try to read preprocessed data train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>merged_tokens_one</th>\n",
              "      <th>merged_tokens_many</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>There have been many movies featuring Bigfoot,...</td>\n",
              "      <td>mani movi featur bigfoot major good least goof...</td>\n",
              "      <td>mani movi featur bigfoot major good least goof...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The plot: A crime lord is uniting 3 different ...</td>\n",
              "      <td>plot crime lord unit differ mafia entrepris bu...</td>\n",
              "      <td>plot crime lord unit differ mafia entrepris bu...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's great to hear the 3 or so comments, that ...</td>\n",
              "      <td>great hear comment point footbal wive signifi ...</td>\n",
              "      <td>great hear comment point footbal wive signifi ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A great story, based on a true story about a y...</td>\n",
              "      <td>great stori base true stori young black man di...</td>\n",
              "      <td>great stori base true stori young black man di...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This film is the proof that a good actor is no...</td>\n",
              "      <td>film proof good actor noth without good direct...</td>\n",
              "      <td>film proof good actor noth without good direct...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review   \n",
              "0  There have been many movies featuring Bigfoot,...  \\\n",
              "1  The plot: A crime lord is uniting 3 different ...   \n",
              "2  It's great to hear the 3 or so comments, that ...   \n",
              "3  A great story, based on a true story about a y...   \n",
              "4  This film is the proof that a good actor is no...   \n",
              "\n",
              "                                   merged_tokens_one   \n",
              "0  mani movi featur bigfoot major good least goof...  \\\n",
              "1  plot crime lord unit differ mafia entrepris bu...   \n",
              "2  great hear comment point footbal wive signifi ...   \n",
              "3  great stori base true stori young black man di...   \n",
              "4  film proof good actor noth without good direct...   \n",
              "\n",
              "                                  merged_tokens_many sentiment   \n",
              "0  mani movi featur bigfoot major good least goof...  negative  \\\n",
              "1  plot crime lord unit differ mafia entrepris bu...  positive   \n",
              "2  great hear comment point footbal wive signifi ...  negative   \n",
              "3  great stori base true stori young black man di...  positive   \n",
              "4  film proof good actor noth without good direct...  negative   \n",
              "\n",
              "   sentiment_number  \n",
              "0                 0  \n",
              "1                 1  \n",
              "2                 0  \n",
              "3                 1  \n",
              "4                 0  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "read_train = pd.read_csv( folder_path+\"processed_movie_dataset_train.csv\" )\n",
        "read_train.head( 5 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### try to read preprocessed data test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>merged_tokens_one</th>\n",
              "      <th>merged_tokens_many</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I gave this movie a chance only because it had...</td>\n",
              "      <td>gave movi chanc good review see trailer though...</td>\n",
              "      <td>gave movi chanc good review. see trailer thoug...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is full of major spoilers, so beware.&lt;br ...</td>\n",
              "      <td>full major spoiler bewar prix de beaut alway s...</td>\n",
              "      <td>full major spoiler bewar. prix de beaut alway ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Never saw the original movie in the series...I...</td>\n",
              "      <td>never saw origin movi seri hope much better mo...</td>\n",
              "      <td>never saw origin movi seri hope much better mo...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This is a film that is far more enjoyable than...</td>\n",
              "      <td>film far enjoy rate would suggest mani way lik...</td>\n",
              "      <td>film far enjoy rate would suggest. mani way li...</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This was intolerable. (SPOILER #1) Protagonist...</td>\n",
              "      <td>intoler spoiler protagonist avoid pointless di...</td>\n",
              "      <td>intoler. spoiler protagonist avoid pointless d...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review   \n",
              "0  I gave this movie a chance only because it had...  \\\n",
              "1  This is full of major spoilers, so beware.<br ...   \n",
              "2  Never saw the original movie in the series...I...   \n",
              "3  This is a film that is far more enjoyable than...   \n",
              "4  This was intolerable. (SPOILER #1) Protagonist...   \n",
              "\n",
              "                                   merged_tokens_one   \n",
              "0  gave movi chanc good review see trailer though...  \\\n",
              "1  full major spoiler bewar prix de beaut alway s...   \n",
              "2  never saw origin movi seri hope much better mo...   \n",
              "3  film far enjoy rate would suggest mani way lik...   \n",
              "4  intoler spoiler protagonist avoid pointless di...   \n",
              "\n",
              "                                  merged_tokens_many sentiment   \n",
              "0  gave movi chanc good review. see trailer thoug...  negative  \\\n",
              "1  full major spoiler bewar. prix de beaut alway ...  positive   \n",
              "2  never saw origin movi seri hope much better mo...  negative   \n",
              "3  film far enjoy rate would suggest. mani way li...  positive   \n",
              "4  intoler. spoiler protagonist avoid pointless d...  negative   \n",
              "\n",
              "   sentiment_number  \n",
              "0                 0  \n",
              "1                 1  \n",
              "2                 0  \n",
              "3                 1  \n",
              "4                 0  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "read_test = pd.read_csv( folder_path+\"processed_movie_dataset_test.csv\" )\n",
        "read_test.head( 5 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (optional) try to create features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to create a vectorizer with sklearn countvectorizer function\n",
        "def create_vectorizer( input_docs, ngram_start=1, ngram_end=1 ):\n",
        "  # create a corpus from input documents\n",
        "  corpus = \" \".join( input_docs )\n",
        "\n",
        "  # create a CountVectorizer object with desired n-gram range\n",
        "  vectorizer = CountVectorizer( ngram_range=( ngram_start, ngram_end ), binary=True )\n",
        "\n",
        "  # fit the vectorizer to the concatenated corpus\n",
        "  vectorizer.fit( [ corpus ] )\n",
        "\n",
        "  # get the shared vocabulary of n-grams\n",
        "  vocabulary = vectorizer.get_feature_names_out()\n",
        "\n",
        "  # return vocab list and the vectrizer obj\n",
        "  return vocabulary, vectorizer\n",
        "# end func"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### create features from sampled data only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len of unigram_vocab: 43363\n",
            "len of bigram_vocab: 731612\n",
            "len of trigram_vocab: 1128636\n",
            "len of unibigram_vocab: 774975\n",
            "len of unibitrigram_vocab: 1903611\n"
          ]
        }
      ],
      "source": [
        "# create ngrams for models from original sampled data\n",
        "unigram_vocab, unigram_vectorizer           = create_vectorizer( read_ori['merged_tokens_one'], 1, 1 )\n",
        "bigram_vocab, bigram_vectorizer             = create_vectorizer( read_ori['merged_tokens_one'], 2, 2 )\n",
        "trigram_vocab, trigram_vectorizer           = create_vectorizer( read_ori['merged_tokens_one'], 3, 3 )\n",
        "unibigram_vocab, unibigram_vectorizer       = create_vectorizer( read_ori['merged_tokens_one'], 1, 2 )\n",
        "unibitrigram_vocab, unibitrigram_vectorizer = create_vectorizer( read_ori['merged_tokens_one'], 1, 3 )\n",
        "\n",
        "# check current length of vocabulary on each ngram vectorizer\n",
        "print( \"len of unigram_vocab:\", len( unigram_vocab ) )\n",
        "print( \"len of bigram_vocab:\", len( bigram_vocab ) )\n",
        "print( \"len of trigram_vocab:\", len( trigram_vocab ) )\n",
        "print( \"len of unibigram_vocab:\", len( unibigram_vocab ) )\n",
        "print( \"len of unibitrigram_vocab:\", len( unibitrigram_vocab ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### create features from train set only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len of unigram_vocab: 38837\n",
            "len of bigram_vocab: 609699\n",
            "len of trigram_vocab: 911622\n",
            "len of unibigram_vocab: 648536\n",
            "len of unibitrigram_vocab: 1560158\n"
          ]
        }
      ],
      "source": [
        "# create ngrams for models from train set\n",
        "unigram_vocab, unigram_vectorizer           = create_vectorizer( read_train['merged_tokens_one'], 1, 1 )\n",
        "bigram_vocab, bigram_vectorizer             = create_vectorizer( read_train['merged_tokens_one'], 2, 2 )\n",
        "trigram_vocab, trigram_vectorizer           = create_vectorizer( read_train['merged_tokens_one'], 3, 3 )\n",
        "unibigram_vocab, unibigram_vectorizer       = create_vectorizer( read_train['merged_tokens_one'], 1, 2 )\n",
        "unibitrigram_vocab, unibitrigram_vectorizer = create_vectorizer( read_train['merged_tokens_one'], 1, 3 )\n",
        "\n",
        "# check current length of vocabulary on each ngram vectorizer\n",
        "print( \"len of unigram_vocab:\", len( unigram_vocab ) )\n",
        "print( \"len of bigram_vocab:\", len( bigram_vocab ) )\n",
        "print( \"len of trigram_vocab:\", len( trigram_vocab ) )\n",
        "print( \"len of unibigram_vocab:\", len( unibigram_vocab ) )\n",
        "print( \"len of unibitrigram_vocab:\", len( unibitrigram_vocab ) )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "KzMEeOkavMjV",
        "3ebk9Wc27HcE",
        "i41PFBuDid6R",
        "KSOxmqO3KtpN",
        "T2poRHkNKzGK",
        "v4cZOKjENEX2",
        "SooSBRtbwXrt",
        "qv7YPnuexT88"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
